{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\envs\\CityNav\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from gym_citynav.utils.unrealcv_basic import UnrealCV\n",
    "from gym_citynav.utils.unrealcv_basic_with_traffic import UnrealCV\n",
    "from gym_citynav.utils.environment_generator_with_traffic import EnvironmentGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__init__:230:Got connection confirm: b'connected to gym_citynav'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=>Info: using ip-port socket\n"
     ]
    }
   ],
   "source": [
    "unrealcv = UnrealCV(port=9000, ip='127.0.0.1', resolution=(1280, 960))\n",
    "# resolution = (1280, 900)\n",
    "# # time.sleep(1)\n",
    "# unrealcv.client.request(\"vset /camera/1/size {} {}\".format(resolution[0], resolution[1]))\n",
    "# unrealcv.client.request(\"vset /camera/1/size {} {}\".format(resolution[0], resolution[1]))\n",
    "# unrealcv.client.request(\"vset /camera/1/reflection Lumen\")\n",
    "# unrealcv.client.request(\"vset /camera/1/illumination Lumen\")\n",
    "# unrealcv.client.request(\"vset /camera/1/exposure_bias 4.5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import time\n",
    "def save(frames, output_path, start_frame):\n",
    "    \"\"\"\n",
    "    Save images\n",
    "    \"\"\"\n",
    "    current_frame = start_frame\n",
    "    for frame in frames:\n",
    "        image = frame\n",
    "        path = os.path.join(os.getcwd(), output_path, f\"{current_frame}.png\")\n",
    "        # print(\"save images to \", path)\n",
    "        os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "        # save image to folder\n",
    "        cv2.imwrite(path, image)\n",
    "        current_frame += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PawnSensor', 'FusionCamSensor']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unrealcv.get_cameras()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m unrealcv\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mrequest(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvset /camera/\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m/exposure_bias 0\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(camera_num))\n\u001b[0;32m     14\u001b[0m unrealcv\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mrequest(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvset /camera/\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m/exposure_bias 6\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(camera_num))\n\u001b[1;32m---> 15\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43munrealcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_image\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlit\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m frames\u001b[38;5;241m.\u001b[39mappend(img)\n",
      "File \u001b[1;32md:\\github\\simworld\\gym_citynav\\gym_citynav\\utils\\unrealcv_basic_with_traffic.py:114\u001b[0m, in \u001b[0;36mUnrealCV.read_image\u001b[1;34m(self, cam_id, viewmode, mode, img_path)\u001b[0m\n\u001b[0;32m    112\u001b[0m         \u001b[38;5;66;03m# image = read_png(self.client.request(cmd))\u001b[39;00m\n\u001b[0;32m    113\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlock:\n\u001b[1;32m--> 114\u001b[0m             image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decode_png(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfile\u001b[39m\u001b[38;5;124m'\u001b[39m:  \u001b[38;5;66;03m# save image to file and read it\u001b[39;00m\n\u001b[0;32m    116\u001b[0m     img_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(os\u001b[38;5;241m.\u001b[39mgetcwd(), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcam_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mviewmode\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.png\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\anaconda\\envs\\CityNav\\lib\\site-packages\\unrealcv\\__init__.py:476\u001b[0m, in \u001b[0;36mClient.request\u001b[1;34m(self, message, timeout)\u001b[0m\n\u001b[0;32m    473\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend_message_id \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    475\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecv_num_q\u001b[38;5;241m.\u001b[39mput(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# negative number indicates need results\u001b[39;00m\n\u001b[1;32m--> 476\u001b[0m message \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_data_q\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    478\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m message\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# time.sleep(6)\n",
    "fps = 30\n",
    "frames = []\n",
    "camera_num = 1\n",
    "resolution = (1920, 1080)\n",
    "# time.sleep(1)\n",
    "unrealcv.client.request(\"vset /camera/{}/size {} {}\".format(camera_num, resolution[0], resolution[1]))\n",
    "unrealcv.client.request(\"vset /camera/{}/reflection Lumen\".format(camera_num))\n",
    "unrealcv.client.request(\"vset /camera/{}/illumination Lumen\".format(camera_num))\n",
    "unrealcv.client.request(\"vset /camera/{}/exposure_bias 4.5\".format(camera_num))\n",
    "# unrealcv.client.request(\"vset /camera/1/exposure_bias 4.5\")\n",
    "while True:\n",
    "    unrealcv.client.request(\"vset /camera/{}/exposure_bias 0\".format(camera_num))\n",
    "    unrealcv.client.request(\"vset /camera/{}/exposure_bias 6\".format(camera_num))\n",
    "    img = unrealcv.read_image(\"1\", \"lit\")\n",
    "    frames.append(img)\n",
    "    # time.sleep(1/fps)\n",
    "# cv2.imshow(\"img\", img)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "222"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save(frames, \"output_videos/images/single_agent/orientation\", 0)\n",
    "# save(frames, \"output_videos/images/single_agent/move_along_road\", 0)\n",
    "# save(frames, \"output_videos/images/single_agent/turning\", 0)\n",
    "save(frames, \"output_videos/images/different_agents/meta_human_run\", 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Renamed 226 files in 'output_videos\\images\\different_agents\\meta_human_run'\n",
      "ğŸ¬ Rendering video: different_agents_meta_human_run.mp4\n",
      "âœ… Video rendering complete.\n"
     ]
    }
   ],
   "source": [
    "rename_frames(\"output_videos/images/different_agents/meta_human_run\")\n",
    "render_video(\"output_videos/images/different_agents/meta_human_run\", output=\"different_agents_meta_human_run.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_frames(\"output_videos/images/single_agent/orientation\")\n",
    "rename_frames(\"output_videos/images/single_agent/move_along_road\")\n",
    "rename_frames(\"output_videos/images/single_agent/turning\")\n",
    "rename_frames(\"output_videos/images/single_agent/find_destination\")\n",
    "render_video(\"output_videos/images/single_agent/orientation\", output=\"orentation.mp4\")\n",
    "render_video(\"output_videos/images/single_agent/move_along_road\", output=\"move_along_road.mp4\")\n",
    "render_video(\"output_videos/images/single_agent/turning\", output=\"turning.mp4\")\n",
    "render_video(\"output_videos/images/single_agent/find_destination\", output=\"find_destination.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_video_from_images(image_path, video_path, fps=10):\n",
    "    import imageio\n",
    "    import os\n",
    "\n",
    "    # å›¾åƒæ–‡ä»¶å¤¹è·¯å¾„\n",
    "    image_folder = image_path\n",
    "    # è§†é¢‘è¾“å‡ºè·¯å¾„\n",
    "    output_video = video_path\n",
    "\n",
    "    # è·å–æ‰€æœ‰å›¾åƒæ–‡ä»¶å¹¶æŒ‰æ–‡ä»¶åæ•°å­—é¡ºåºæ’åº\n",
    "    images = os.listdir(image_folder)\n",
    "    images.sort(key=lambda x: int(x.split('.')[0]))\n",
    "    print(images)\n",
    "    images = [os.path.join(image_folder, image) for image in images]\n",
    "\n",
    "    # åˆ›å»ºä¸€ä¸ªè§†é¢‘å†™å…¥å¯¹è±¡\n",
    "    with imageio.get_writer(output_video, fps=fps) as writer:\n",
    "        for image_name in images:\n",
    "            image_path = os.path.join(image_folder, image_name)\n",
    "            image = imageio.imread(image_path)  # è¯»å–å›¾åƒ\n",
    "            writer.append_data(image)  # å°†å›¾åƒå†™å…¥è§†é¢‘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "def rename_frames(input_dir, prefix=\"frame_\", ext=\"png\"):\n",
    "    \"\"\"\n",
    "    Rename all image files in the input directory to the format: prefix_0001.ext, prefix_0002.ext, ...\n",
    "    \n",
    "    Args:\n",
    "        input_dir (str or Path): Path to the folder containing the images.\n",
    "        prefix (str): Prefix for renamed files (default: 'frame_').\n",
    "        ext (str): Extension of the image files (default: 'png').\n",
    "    \"\"\"\n",
    "    input_dir = Path(input_dir)\n",
    "    if not input_dir.exists():\n",
    "        raise FileNotFoundError(f\"Directory not found: {input_dir}\")\n",
    "    \n",
    "    # è·å–æ‰€æœ‰ç›®æ ‡æ–‡ä»¶\n",
    "    files = sorted(input_dir.glob(f\"*.{ext}\"), key=lambda f: int(f.stem))\n",
    "    \n",
    "    for i, file in enumerate(files, start=1):\n",
    "        new_name = input_dir / f\"{prefix}{i:04d}.{ext}\"\n",
    "        file.rename(new_name)\n",
    "    \n",
    "    print(f\"âœ… Renamed {len(files)} files in '{input_dir}'\")\n",
    "\n",
    "def render_video(input_dir, prefix=\"frame_\", ext=\"png\", fps=30, output=\"output.mp4\"):\n",
    "    \"\"\"\n",
    "    Use FFmpeg to render a video from image frames.\n",
    "\n",
    "    Args:\n",
    "        input_dir (str or Path): Folder containing renamed frames.\n",
    "        prefix (str): Prefix of frame files.\n",
    "        ext (str): File extension (default: 'png').\n",
    "        fps (int): Frames per second for the video.\n",
    "        output (str): Output video filename.\n",
    "    \"\"\"\n",
    "    input_dir = Path(input_dir)\n",
    "    input_pattern = str(input_dir / f\"{prefix}%04d.{ext}\")\n",
    "\n",
    "    cmd = [\n",
    "        \"ffmpeg\",\n",
    "        \"-framerate\", str(fps),\n",
    "        \"-i\", input_pattern,\n",
    "        \"-s\", \"1280x900\",\n",
    "        \"-c:v\", \"libx264\",\n",
    "        \"-pix_fmt\", \"yuv420p\",\n",
    "        output\n",
    "    ]\n",
    "\n",
    "    print(f\"ğŸ¬ Rendering video: {output}\")\n",
    "    subprocess.run(cmd, check=True)\n",
    "    print(\"âœ… Video rendering complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "orientation_task \n",
    "(-6972.0, 7756.0ï¼Œ 58) (0, 0, 90)\n",
    "move along road task\n",
    "(-6972.0, 7756.0ï¼Œ 58) (0, 0, 0)\n",
    "Turning Task:\n",
    "(-3971.999508, 7756.0ï¼Œ 63.056413) (0,0,0)\n",
    "Find Destination:\n",
    "(-1346.999078, 7756.0, 59.945384) (0, 0, 90)\n",
    "Destination:\n",
    "(-1346.999078, 10206.000402, 59.945384) (0, 0, 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "beginning location\n",
    "(-3499.0, 7860.0ï¼Œ 60.0) (0ï¼Œ 0ï¼Œ 0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(r'D:\\github\\SimWorld\\case study\\single\\trajectory.csv')\n",
    "column_data = df['action']\n",
    "values = column_data.dropna().tolist()\n",
    "filtered = [x for x in values if x != -1.0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unrealcv = UnrealCV(port=9000, ip='127.0.0.1', resolution=(1280, 960))\n",
    "world_json = r\"D:\\github\\SimWorld\\case study\\single\\task_dist_11_0_1\\progen_world.json\"\n",
    "road_json = r\"D:\\github\\SimWorld\\case study\\single\\task_dist_11_0_1\\roads.json\"\n",
    "# unrealcv = UnrealCV(port=9000, ip='127.0.0.1', resolution=(1920, 1080))\n",
    "world_generator = EnvironmentGenerator(unrealcv)\n",
    "# Clean the environment\n",
    "world_generator.clear_env()\n",
    "# world_generator = EnvironmentGenerator(unrealcv)\n",
    "# # Clean the environment\n",
    "# world_generator.clear_env()\n",
    "# Loading Json\n",
    "world_generator.loading_json(world_json)\n",
    "# Generate World\n",
    "world_generator.generate_world()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robot_name = \"spot_robot\" \n",
    "unrealcv.spawn_bp_asset(\"/Game/Robot_Dog/Blueprint/BP_SpotRobot.BP_SpotRobot_C\", robot_name)\n",
    "camera_num = 1\n",
    "unrealcv.client.request(\"vset /camera/{}/reflection Lumen\".format(camera_num))\n",
    "unrealcv.client.request(\"vset /camera/{}/illumination Lumen\".format(camera_num))\n",
    "# unrealcv.client.request(\"vset /camera/{}/exposure_bias 4.5\".format(camera_num))\n",
    "resolution = (1280, 900)\n",
    "# time.sleep(1)\n",
    "unrealcv.client.request(\"vset /camera/{}/size {} {}\".format(camera_num, resolution[0], resolution[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "unrealcv.enable_controller(robot_name, True)\n",
    "unrealcv.set_location_hard([-45154.5228, -61700.0, 73.957685], robot_name)\n",
    "unrealcv.set_orientation_hard([0, 0, 90], robot_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "fps = 30\n",
    "frames = []\n",
    "camera_num = 1\n",
    "# test_actions = [5.0, 0.0, 0.0]\n",
    "for action in filtered:\n",
    "    if action == 4.0:\n",
    "        unrealcv.apply_action_rotation(robot_name, [0.5, 90, 1])\n",
    "    elif action == 5.0:\n",
    "        unrealcv.apply_action_rotation(robot_name, [0.5, -90, -1])\n",
    "    elif action == 0.0:\n",
    "        unrealcv.apply_action_transition(robot_name, [500, 1, 0])\n",
    "    available = False\n",
    "    while not available:\n",
    "        # unrealcv.client.request(\"vset /camera/{}/exposure_bias 0\".format(camera_num))\n",
    "        # unrealcv.client.request(\"vset /camera/{}/exposure_bias 6\".format(camera_num))\n",
    "        img = unrealcv.read_image(\"1\", \"lit\")\n",
    "        frames.append(img)\n",
    "        time.sleep(1/fps)\n",
    "        available = unrealcv.get_is_available(robot_name)\n",
    "        # print(available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "save(frames, \"output_videos/images/single_agent_qualitive/\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename_frames(\"output_videos/images/single_agent_qualitive\")\n",
    "render_video(\"output_videos/images/single_agent_qualitive\", output=\"case_1_updated.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "# è®¾ç½®è·¯å¾„\n",
    "input_folder = r'D:\\github\\SimWorld\\output_videos\\images\\images2litup'      # è¾“å…¥å›¾ç‰‡æ‰€åœ¨æ–‡ä»¶å¤¹\n",
    "output_folder = r'D:\\github\\SimWorld\\output_videos\\images\\brightened' # è¾“å‡ºä¿å­˜çš„æ–°å›¾ç‰‡æ–‡ä»¶å¤¹\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# è°ƒæ•´äº®åº¦çš„å‚æ•°\n",
    "alpha = 1.0  # å¯¹æ¯”åº¦ï¼ˆ1.0 è¡¨ç¤ºä¸å˜ï¼‰\n",
    "beta = 20    # äº®åº¦ï¼ˆå¢åŠ æ•°å€¼ä¼šå˜äº®ï¼‰\n",
    "\n",
    "# éå†æ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰å›¾ç‰‡\n",
    "for filename in os.listdir(input_folder):\n",
    "    if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp')):\n",
    "        img_path = os.path.join(input_folder, filename)\n",
    "        img = cv2.imread(img_path)\n",
    "\n",
    "        if img is None:\n",
    "            print(f\"è·³è¿‡æ— æ•ˆå›¾ç‰‡: {filename}\")\n",
    "            continue\n",
    "\n",
    "        # æé«˜äº®åº¦\n",
    "        bright_img = cv2.convertScaleAbs(img, alpha=alpha, beta=beta)\n",
    "\n",
    "        # ä¿å­˜ç»“æœ\n",
    "        out_path = os.path.join(output_folder, filename)\n",
    "        cv2.imwrite(out_path, bright_img)\n",
    "\n",
    "print(\"æ‰€æœ‰å›¾ç‰‡äº®åº¦å·²è°ƒé«˜å¹¶ä¿å­˜åˆ°è¾“å‡ºæ–‡ä»¶å¤¹ã€‚\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unrealcv = UnrealCV(port=9000, ip='127.0.0.1', resolution=(1280, 960))\n",
    "world_json = r\"D:\\github\\SimWorld\\case study\\multi\\task_dist_1_1\\progen_world.json\"\n",
    "road_json = r\"D:\\github\\SimWorld\\case study\\multi\\task_dist_1_1\\roads.json\"\n",
    "# unrealcv = UnrealCV(port=9000, ip='127.0.0.1', resolution=(1920, 1080))\n",
    "world_generator = EnvironmentGenerator(unrealcv)\n",
    "# Clean the environment\n",
    "world_generator.clear_env()\n",
    "# world_generator = EnvironmentGenerator(unrealcv)\n",
    "# # Clean the environment\n",
    "# world_generator.clear_env()\n",
    "# Loading Json\n",
    "world_generator.loading_json(world_json)\n",
    "# Generate World\n",
    "world_generator.generate_world()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(r'D:\\github\\SimWorld\\case study\\multi\\multi-success-case-main-trajectory.csv')\n",
    "column_data = df['action']\n",
    "values = column_data.dropna().tolist()\n",
    "main_agent_actions = [x for x in values if x != 100]\n",
    "\n",
    "df = pd.read_csv(r'D:\\github\\SimWorld\\case study\\multi\\multi-success-case-follower-trajectory.csv')\n",
    "column_data = df['action']\n",
    "values = column_data.dropna().tolist()\n",
    "follower_agent_actions = [x for x in values if x != 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(main_agent_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(follower_agent_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ok'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "robot_name_1 = \"spot_robot_1\" \n",
    "unrealcv.spawn_bp_asset(\"/Game/Robot_Dog/Blueprint/BP_SpotRobot.BP_SpotRobot_C\", robot_name_1)\n",
    "robot_1_camera = 1\n",
    "unrealcv.client.request(\"vset /camera/{}/reflection Lumen\".format(robot_1_camera))\n",
    "unrealcv.client.request(\"vset /camera/{}/illumination Lumen\".format(robot_1_camera))\n",
    "# unrealcv.client.request(\"vset /camera/{}/exposure_bias 4.5\".format(camera_num))\n",
    "resolution = (1280, 900)\n",
    "# time.sleep(1)|\n",
    "unrealcv.client.request(\"vset /camera/{}/size {} {}\".format(robot_1_camera, resolution[0], resolution[1]))\n",
    "\n",
    "robot_name_2 = \"spot_robot_2\" \n",
    "unrealcv.spawn_bp_asset(\"/Game/Robot_Dog/Blueprint/BP_SpotRobot.BP_SpotRobot_C\", robot_name_2)\n",
    "robot_2_camera = 2\n",
    "unrealcv.client.request(\"vset /camera/{}/reflection Lumen\".format(robot_2_camera))\n",
    "unrealcv.client.request(\"vset /camera/{}/illumination Lumen\".format(robot_2_camera))\n",
    "# unrealcv.client.request(\"vset /camera/{}/exposure_bias 4.5\".format(camera_num))\n",
    "resolution = (1280, 900)\n",
    "# time.sleep(1)\n",
    "unrealcv.client.request(\"vset /camera/{}/size {} {}\".format(robot_2_camera, resolution[0], resolution[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "unrealcv.enable_controller(robot_name_1, True)\n",
    "unrealcv.set_location_hard([34419.4805, -1700.0, 73.957685], robot_name_1)\n",
    "unrealcv.set_orientation_hard([0, 0, -90], robot_name_1)\n",
    "\n",
    "unrealcv.enable_controller(robot_name_2, True)\n",
    "unrealcv.set_location_hard([61700.0, -9406.5421, 73.957685], robot_name_2)\n",
    "unrealcv.set_orientation_hard([0, 0, 0], robot_name_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import time\n",
    "fps = 30\n",
    "frames = []\n",
    "camera_num = 1\n",
    "# test_actions = [5.0, 0.0, 0.0]\n",
    "\n",
    "for i in range(len(follower_agent_actions)):\n",
    "    agent_1_action = 100\n",
    "    if i < len(main_agent_actions):\n",
    "        agent_1_action = main_agent_actions[i]\n",
    "    agent_2_action = follower_agent_actions[i]\n",
    "    if agent_1_action != 100:\n",
    "        if agent_1_action == 4.0:\n",
    "            unrealcv.apply_action_rotation(robot_name_1, [1, 90, 1])\n",
    "        elif agent_1_action == 5.0:\n",
    "            unrealcv.apply_action_rotation(robot_name_1, [1, -90, -1])\n",
    "        elif agent_1_action == 0.0:\n",
    "            unrealcv.apply_action_transition(robot_name_1, [500, 1, 0])\n",
    "    \n",
    "    if agent_2_action == 4.0:\n",
    "        unrealcv.apply_action_rotation(robot_name_2, [1, 90, 1])\n",
    "    elif agent_2_action == 5.0:\n",
    "        unrealcv.apply_action_rotation(robot_name_2, [1, -90, -1])\n",
    "    elif agent_2_action == 0.0:\n",
    "        unrealcv.apply_action_transition(robot_name_2, [500, 1, 0])\n",
    "    available = False\n",
    "    while not available:\n",
    "        # # unrealcv.client.request(\"vset /camera/{}/exposure_bias 0\".format(camera_num))\n",
    "        # # unrealcv.client.request(\"vset /camera/{}/exposure_bias 6\".format(camera_num))\n",
    "        img = unrealcv.read_image(\"1\", \"lit\")\n",
    "        frames.append(img)\n",
    "        time.sleep(1/fps)\n",
    "        # time.sleep(0.2)\n",
    "        available = unrealcv.get_is_available(robot_name_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save(frames, \"output_videos/images/multi_agent_qualitive/follower\", 0)\n",
    "save(frames, \"output_videos/images/multi_agent_qualitive/main\", 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ‰€æœ‰å›¾ç‰‡äº®åº¦å·²è°ƒé«˜å¹¶ä¿å­˜åˆ°è¾“å‡ºæ–‡ä»¶å¤¹ã€‚\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "# è®¾ç½®è·¯å¾„\n",
    "input_folder = r'D:\\github\\SimWorld\\output_videos\\images\\images2litup'      # è¾“å…¥å›¾ç‰‡æ‰€åœ¨æ–‡ä»¶å¤¹\n",
    "output_folder = r'D:\\github\\SimWorld\\output_videos\\images\\brightened' # è¾“å‡ºä¿å­˜çš„æ–°å›¾ç‰‡æ–‡ä»¶å¤¹\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# è°ƒæ•´äº®åº¦çš„å‚æ•°\n",
    "alpha = 1.0  # å¯¹æ¯”åº¦ï¼ˆ1.0 è¡¨ç¤ºä¸å˜ï¼‰\n",
    "beta = 20    # äº®åº¦ï¼ˆå¢åŠ æ•°å€¼ä¼šå˜äº®ï¼‰\n",
    "\n",
    "# éå†æ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰å›¾ç‰‡\n",
    "for filename in os.listdir(input_folder):\n",
    "    if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp')):\n",
    "        img_path = os.path.join(input_folder, filename)\n",
    "        img = cv2.imread(img_path)\n",
    "\n",
    "        if img is None:\n",
    "            print(f\"è·³è¿‡æ— æ•ˆå›¾ç‰‡: {filename}\")\n",
    "            continue\n",
    "\n",
    "        # æé«˜äº®åº¦\n",
    "        bright_img = cv2.convertScaleAbs(img, alpha=alpha, beta=beta)\n",
    "\n",
    "        # ä¿å­˜ç»“æœ\n",
    "        out_path = os.path.join(output_folder, filename)\n",
    "        cv2.imwrite(out_path, bright_img)\n",
    "\n",
    "print(\"æ‰€æœ‰å›¾ç‰‡äº®åº¦å·²è°ƒé«˜å¹¶ä¿å­˜åˆ°è¾“å‡ºæ–‡ä»¶å¤¹ã€‚\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¬ Rendering video: multi_qualitive_main.mp4\n",
      "âœ… Video rendering complete.\n"
     ]
    }
   ],
   "source": [
    "# rename_frames(r\"D:\\github\\SimWorld\\output_videos\\images\\multi_agent_qualitive\\follower\")\n",
    "# rename_frames(r\"D:\\github\\SimWorld\\output_videos\\images\\multi_agent_qualitive\\main\")\n",
    "# render_video(r\"D:\\github\\SimWorld\\output_videos\\images\\multi_agent_qualitive\\follower\", output=\"multi_qualitive_follower.mp4\")\n",
    "render_video(r\"D:\\github\\SimWorld\\output_videos\\images\\multi_agent_qualitive\\main\", output=\"multi_qualitive_main.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CityNav",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
