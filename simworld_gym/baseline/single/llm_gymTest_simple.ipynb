{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c883e8a-6f33-4181-a7ab-ae9dc5d10e3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9998\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import simworld_gym\n",
    "import os\n",
    "\n",
    "ue_port = int(os.getenv('UE_PORT', '2000'))\n",
    "print(ue_port)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf33102-eb36-4315-ad78-6d1c42278a96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__init__:230:Got connection confirm: b'connected to gym_citynav'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=>Info: using ip-port socket\n"
     ]
    }
   ],
   "source": [
    "# Define the reward_setting dictionary\n",
    "reward_setting = {\n",
    "    \"human_collision_penalty\": -1,  # Penalty for colliding with humans\n",
    "    \"object_collision_penalty\": -0.1,  # Penalty for colliding with objects\n",
    "    \"action_penalty\": -0.1,            # Penalty for each action (encourages shorter paths)\n",
    "    \"success_reward\": 10.0,           # Reward for successfully reaching the goal\n",
    "    \"off_track_penalty\": -0.01          # Penalty for going off track\n",
    "}\n",
    "\n",
    "model = \"gpt-5\"\n",
    "\n",
    "# Use this reward_setting in gym.make\n",
    "env = gym.make('gym_citynav/SimpleWorld-v0',\n",
    "               port=ue_port,\n",
    "               resolution=(720, 600),\n",
    "               render_mode=\"rgb_array\",  \n",
    "               observation_type=\"all\",  \n",
    "               record_video=False,\n",
    "               log_dir=f\"{model}_simple\", \n",
    "               reward_setting=reward_setting,\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9530294",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prompt_template import *\n",
    "from agents import ReasoningAgent\n",
    "import os\n",
    "strip = False\n",
    "full = False\n",
    "depth = False\n",
    "agent = ReasoningAgent(\n",
    "    model=model,\n",
    "    system_prompt=nav_template(full, depth, strip)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87687b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import action_history_text, numpy_to_base64, split_into_strips, display_images, extract_action_dict\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "input_tokens = 0\n",
    "output_tokens = 0\n",
    "worlds = [f\"map_road_20_{i}\" for i in range(52, 75)]\n",
    "task_2_test = [\"task_dist_21_0_1\"]\n",
    "action_mapping = [\"Move_Forward\", \"Rotate_Left\", \"Rotate_Right\", \"Move_Left\", \"Move_Right\", \"Subtask_Complete\"]\n",
    "for world in worlds:\n",
    "    reseted = False\n",
    "    for task in task_2_test:\n",
    "        task_path = os.path.join(\"single_agent_world\", \"easy\", world, task)\n",
    "        world_json = os.path.join(task_path, \"progen_world.json\")\n",
    "        agent_json = os.path.join(task_path, \"task_config.json\")\n",
    "        if not reseted:\n",
    "            options = {\n",
    "                \"task_path\": task_path,\n",
    "                \"agent_json\": agent_json,\n",
    "                \"world_json\": world_json,\n",
    "            }\n",
    "            reseted = True\n",
    "        else:\n",
    "            options = {\n",
    "                \"task_path\": task_path,\n",
    "                \"agent_json\": agent_json,\n",
    "            }\n",
    "        observation, info = env.reset(options=options)\n",
    "        vision_cue = info[\"current_instruction\"][\"image\"]\n",
    "        instruction = info[\"current_instruction\"][\"text\"]\n",
    "        action_history = []\n",
    "        chosen_actions = []\n",
    "        \n",
    "        summary = \"\"\"\n",
    "                Status: Ready to Start. \n",
    "                No obstacles found. \n",
    "                No intersections seen. \n",
    "                The Landmark to be spotted: Just started, unknown.\n",
    "                Have not seen the landmark yet.\n",
    "                \"\"\"\n",
    "        last_vision_descriptions = \"\"\n",
    "        folder_path = os.path.join(\"/SimWorld\", \"agent_log\", f\"{model}_simple\", f\"{world}\", f\"{task}\")\n",
    "        os.makedirs(folder_path , exist_ok=True)\n",
    "\n",
    "        i = 0\n",
    "        terminated = False\n",
    "        last_position = None\n",
    "        current_position = None\n",
    "        parse_failure_count = 0\n",
    "\n",
    "        while not terminated:\n",
    "            orientation = info['agent']['agent_rotation']\n",
    "            current_position = info['agent']['agent_location']\n",
    "            forward_count = 0\n",
    "            for a in chosen_actions:\n",
    "                if a == 0:\n",
    "                    forward_count += 1\n",
    "            if not last_position is None and forward_count > 3 and np.linalg.norm(np.array(current_position) - np.array(last_position)) < 0.5:\n",
    "                print(\"Stuck in place, terminating.\")\n",
    "                with open(os.path.join(folder_path, \"LLM_Output.txt\"), \"a\") as llm_logger:\n",
    "                    llm_logger.write(\"[STUCK]\"'\\n')\n",
    "                break\n",
    "            last_position = current_position\n",
    "            cv2.imwrite(os.path.join(folder_path, f\"{i}.png\"), observation[\"rgb\"])\n",
    "            segment_img = numpy_to_base64(observation[\"object_mask\"])\n",
    "            if strip:\n",
    "                input_imgs = split_into_strips(observation[\"rgb\"])\n",
    "                input_imgs.append(numpy_to_base64(vision_cue))\n",
    "                descriptions = ['The view on the left', 'The horizontal center', 'The right', 'The expected view']\n",
    "            else:\n",
    "                input_imgs = [numpy_to_base64(observation[\"rgb\"]), numpy_to_base64(vision_cue)]\n",
    "                descriptions = ['The current view', 'The expected view']\n",
    "            input_imgs.append(segment_img)\n",
    "            descriptions.append('The object segmentation mask of the current view')\n",
    "\n",
    "            display_images(observation[\"rgb\"], vision_cue)\n",
    "\n",
    "            nav_instance = (\n",
    "                f\"Actions taken: {action_history_text(action_history, action_mapping)}\\n\\n\"\n",
    "                f\"Your Last Move: {chosen_actions}\\n\\n\"\n",
    "                f\"Vision Description Last Step: {last_vision_descriptions}\\n\\n\"\n",
    "                f\"Status of Last Step: {summary}\\n\\n\"\n",
    "                f\"Current Subtask: {instruction}\\n\\n\"\n",
    "                f\"Current Orientation: {orientation}\\n\\n\"\n",
    "            )\n",
    "            result = agent.act(\n",
    "                nav_instance, \n",
    "                input_imgs, \n",
    "                descriptions, \n",
    "            )\n",
    "            result_dict = extract_action_dict(result[\"output\"])\n",
    "            try:\n",
    "                last_vision_descriptions = result_dict.get(\"Description\")\n",
    "                summary = result_dict.get(\"Summary\")\n",
    "                match = result_dict.get(\"Match\")\n",
    "                chosen_actions = result_dict.get(\"Actions\")\n",
    "            except Exception as e:\n",
    "                print(f\"Perception error\")\n",
    "                parse_failure_count += 1\n",
    "                if parse_failure_count > 10:\n",
    "                    print(\"Too many perception errors, terminating.\")\n",
    "                    with open(os.path.join(folder_path, \"LLM_Output.txt\"), \"a\") as llm_logger:\n",
    "                        llm_logger.write(\"[TOO MANY ERRORS]\"'\\n')\n",
    "                    break\n",
    "                continue\n",
    "            print(\"[vision]\", last_vision_descriptions)\n",
    "            print(\"[reason]\", result[\"reason\"])\n",
    "            input_tokens += result[\"usage\"][\"input\"]\n",
    "            output_tokens += result[\"usage\"][\"output\"]\n",
    "            with open(os.path.join(folder_path, \"LLM_Output.txt\"), \"a\") as llm_logger:\n",
    "                llm_logger.write(\"[current subtask]\" + instruction +'\\n')\n",
    "                llm_logger.write(f\"[vision {i}]\" + str(last_vision_descriptions).replace(\"\\n\", \"\") +'\\n')\n",
    "                llm_logger.write(f\"[reason {i}]\" + str(result[\"reason\"]).replace(\"\\n\", \"\") + '\\n')\n",
    "                llm_logger.write(f\"[summary {i}]\" + str(summary).replace(\"\\n\", \"\") + '\\n')\n",
    "                llm_logger.write(f\"[actions {i}]\" + str(chosen_actions) + '\\n')\n",
    "                llm_logger.write(f\"[match {i}]\" + str(match) + '\\n')\n",
    "            if not chosen_actions:\n",
    "                print(\"No action specified. Failing.\")\n",
    "                break\n",
    "            for chosen_action in chosen_actions:\n",
    "                action_history.append(chosen_action)\n",
    "                i += 1\n",
    "                match chosen_action:\n",
    "                    case -1:\n",
    "                        observation, _, terminated, _, info = env.step(-1)\n",
    "                        if terminated:\n",
    "                            print(\"End\")\n",
    "                            break\n",
    "                        instruction = info[\"current_instruction\"][\"text\"]\n",
    "                        vision_cue = info[\"current_instruction\"][\"image\"]\n",
    "                        action_history = []\n",
    "                    case 0:\n",
    "                        observation, _, terminated, _, info = env.step(0)\n",
    "                    case 1:\n",
    "                        observation, _, terminated, _, info = env.step(5)\n",
    "                    case 2:\n",
    "                        observation, _, terminated, _, info = env.step(4)\n",
    "                    case 3:\n",
    "                        observation, _, terminated, _, info = env.step(2)\n",
    "                    case 4:\n",
    "                        observation, _, terminated, _, info = env.step(3)\n",
    "            if terminated:\n",
    "                print(\"End\")\n",
    "                break\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c588f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
